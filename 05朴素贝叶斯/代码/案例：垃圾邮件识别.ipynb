{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 垃圾邮件识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import naive_bayes as nb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVocabList(dataSet):\n",
    "    vocabSet = set([])  #创建空的词汇表\n",
    "    for document in dataSet:\n",
    "        #词汇表和set(document)取并集\n",
    "        vocabSet = vocabSet | set(document) \n",
    "    #返回一个经过自然排序的词汇表\n",
    "    return sorted(list(vocabSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'i', 'love', 'you']\n"
     ]
    }
   ],
   "source": [
    "dataset = [['i','love','you'],\n",
    "           ['he','love','you']]\n",
    "vocablist = createVocabList(dataset)\n",
    "print(vocablist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 词集模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList, inputSet):\n",
    "    #初始化向量，其长度与词汇表长度一致\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            #把词汇表对应位置设为1\n",
    "            returnVec[vocabList.index(word)] = 1\n",
    "        else: print(\"词: %s 不在词汇表中!\" % word)\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'i', 'love', 'you']\n",
      "[0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(vocablist)\n",
    "print(setOfWords2Vec(vocablist,['love','you','you']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 词袋模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWords2Vec(vocabList, inputSet):\n",
    "    #初始化向量，其长度与词汇表长度一致\n",
    "    returnVec = [0]*len(vocabList)\n",
    "    for word in inputSet:\n",
    "        if word in vocabList:\n",
    "            #把词汇表对应位置加1\n",
    "            returnVec[vocabList.index(word)] += 1\n",
    "    return returnVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'i', 'love', 'you']\n",
      "[0, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "print(vocablist)\n",
    "print(bagOfWords2Vec(vocablist,['love','you','you']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对邮件内容的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textParse(bigString):\n",
    "    import re\n",
    "    listOfTokens = re.split(r'\\W*', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['love', 'you']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textParse('I love You')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata():\n",
    "    docList = []\n",
    "    classList = []\n",
    "\n",
    "    num = 26\n",
    "    for i in range(1, num):\n",
    "        wordList = textParse(open('data/email/spam/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(1)\n",
    "        \n",
    "        wordList = textParse(open('data/email/ham/%d.txt' % i).read())\n",
    "        docList.append(wordList)\n",
    "        classList.append(0)\n",
    "        \n",
    "    vocabList = createVocabList(docList)\n",
    "    \n",
    "    X = []\n",
    "    for docIndex in range(len(docList)):\n",
    "        X.append(bagOfWords2Vec(vocabList, docList[docIndex]))\n",
    "        # X.append(setOfWords2Vec(vocabList, docList[docIndex]))\n",
    "        \n",
    "    return X, classList, vocabList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "X,y,vocaList = loaddata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=33, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nb.MultinomialNB()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy=\",accuracy_score(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
